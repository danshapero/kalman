{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import ode\n",
    "\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%aimport lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Kalman filter\n",
    "\n",
    "The Kalman filter is a procedure to estimate the state of a system with known dynamics, but which can only be observed imperfectly.\n",
    "\n",
    "Consider everyone's favorite example, the Lorenz attractor:\n",
    "\n",
    "$\\dot x = \\sigma(y - x)$\n",
    "\n",
    "$\\dot y = x(\\rho - z) - y$\n",
    "\n",
    "$\\dot z = xy - \\beta z$\n",
    "\n",
    "Given an initial condition $[x_0, y_0, z_0]$, we can use our favorite ODE solver to compute the trajectory of this initial condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = lorenz.lorenz([5.0, 5.0, 5.0], 0.0, 10.0)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot(q[:,0], q[:,1], q[:,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we only get to observe the system at discrete time intervals?\n",
    "\n",
    "What if we don't even get to observe the system, just the output of some sensor?\n",
    "\n",
    "And what if the sensor makes errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = lorenz.observational_data\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(d[:,0], d[:,1], d[:,2], color='r', marker='.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we use the (admittedly noisy) observations together with what we know about the underlying system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some stats\n",
    "\n",
    "There's a random variable $x$ we'd like to estimate; we already have an unbiased estimate $\\hat x_0$, that is,\n",
    "\n",
    "$$ \\hat x_0 = x + \\xi, $$\n",
    "\n",
    "where $\\xi \\sim N(0, C)$ for some covariance matrix $C$.\n",
    "Never mind where $\\hat x_0$ came from for now, we'll get to that.\n",
    "\n",
    "Now we get a measurement $y$ of $x$:\n",
    "\n",
    "$$ y = Mx + \\eta $$\n",
    "\n",
    "where $\\eta \\sim N(0, Q)$.\n",
    "Updated estimate $\\hat x$ has the maximum a posteriori probability:\n",
    "\n",
    "$$ \\hat x = \\hat x_0 + CM^*(MCM^* + Q)^{-1}(y - M\\hat x_0) $$\n",
    "\n",
    "The new estimate has\n",
    "\n",
    "$$ \\textrm{cov}(\\hat x) = C - CM^*(MCM^* + Q)^{-1}MC. $$\n",
    "\n",
    "Observe that $\\textrm{cov}(\\hat x) \\le \\textrm{cov}(\\hat x_0)$.\n",
    "(Derivations on the board if you want to see them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%aimport mle\n",
    "nn = 16\n",
    "\n",
    "# True vector to be estimated\n",
    "z = np.array(map(lambda k: np.sin(2 * np.pi * k / nn), range(nn)))\n",
    "\n",
    "L = np.zeros((nn, nn))\n",
    "for i in range(nn):\n",
    "    j = (i + 1) % nn\n",
    "    L[i, i] = 1.0\n",
    "    L[i, j] = 0.5\n",
    "\n",
    "sigma_process = 0.25\n",
    "    \n",
    "# A priori estimate and covariance\n",
    "x0 = z + np.dot(L, np.random.randn(nn)) * sigma_process\n",
    "C0 = np.dot(L, L.T) * sigma_process**2\n",
    "\n",
    "# We only get to measure every other point\n",
    "M = np.zeros((nn/2, nn))\n",
    "for i in range(nn):\n",
    "    k = i/2\n",
    "    M[k, i] = 1.0\n",
    "\n",
    "# The measurement errors are white\n",
    "sigma_measurement = 0.25\n",
    "Q = np.eye(nn/2) * sigma_measurement**2\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot the a priori guess in blue\n",
    "plt.plot(range(nn), x0, 'b--', hold = True, linewidth=2.0)\n",
    "\n",
    "# Artificially generate some measurements\n",
    "num_trials = 32\n",
    "for t in range(num_trials):\n",
    "    y = np.dot(M, z) + np.random.randn(nn/2) * sigma_measurement\n",
    "    x, C = mle.update(x0, C0, y, M, Q)\n",
    "\n",
    "    cl = (num_trials - 1.0 * t) / num_trials\n",
    "    plt.plot(range(nn), x, color = (cl, cl, cl), hold = True)\n",
    "\n",
    "    x0 = x\n",
    "    C0 = C\n",
    "\n",
    "# Plot the true vector in red\n",
    "plt.plot(range(nn), z, 'r--', hold = True, linewidth=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear stochastic dynamical systems\n",
    "\n",
    "Consider a discrete dynamical system\n",
    "\n",
    "$$X_k = AX_{k - 1} + \\xi_k.$$\n",
    "\n",
    "$\\xi_k$ is the *process noise*; $\\xi_k \\sim N(0, C)$.\n",
    "\n",
    "However, we don't get to observe the process $X_k$ directly; rather, we only get to see\n",
    "\n",
    "$$Y_k = MX_k + \\eta_k,$$\n",
    "\n",
    "where $\\eta_k \\sim N(0, Q)$ is the *measurement noise*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Say we have an unbiased estimate $\\hat x_{k-1|k-1}$ for $x_{k-1}$ based on the previous $k - 1$ observations, for which we somehow know that\n",
    "\n",
    "$$ \\textrm{cov}(\\hat x_{k-1|k-1}) = P_{k|k-1}. $$\n",
    "\n",
    "How can we update this estimate for the next timestep?\n",
    "\n",
    "$$\\hat x_{k|k-1} \\equiv A\\hat x_{k-1|k-1}$$\n",
    "\n",
    "is unbiased for $x_k$.\n",
    "What happens to the covariance?\n",
    "\n",
    "$$ P_{k|k-1} \\equiv \\textrm{cov}(\\hat x_{k|k-1}) = AP_{k-1|k-1}A^* + C$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction\n",
    "\n",
    "Now we get some data $y_k$; how do we correct our prediction?\n",
    "Well, $\\hat x_{k|k-1}$ is an unbiased estimate for $x_k$, and presumably we know its covariance.\n",
    "But we just did that a second ago; the a prior covariance $C$ is $P_{k|k-1}$:\n",
    "\n",
    "$$ \\hat x_{k|k} = \\hat x_{k|k-1} + K_k(y_k - M\\hat x_{k|k-1}) $$\n",
    "\n",
    "where $K_k$ is the Kalman gain matrix:\n",
    "\n",
    "$$ K_k = P_{k|k-1}M^*(MP_{k|k-1}M^* + Q)^{-1}$$\n",
    "\n",
    "With the updated covariance:\n",
    "\n",
    "$$ P_{k|k} = (I - K_kM)P_{k|k-1}$$\n",
    "\n",
    "we can start over again at step $k$.\n",
    "\n",
    "#### Appease the numerical analysts\n",
    "\n",
    "All this can be done by keeping the Cholesky decomposition of the covariance matrix and not the inverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple demo\n",
    "\n",
    "Let's try this for a discrete-time approximation of the underdamped harmonic oscillator\n",
    "\n",
    "$$ \\ddot x + \\gamma\\dot x + \\omega^2 x = \\sigma^2\\xi_t.$$\n",
    "\n",
    "Letting $p = \\dot x$, this is a 2D, first-order dynamical system.\n",
    "To make things interesting, let's assume we can only measure $x$ but not $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "frequency = 1.0\n",
    "damping_time = 10.0\n",
    "\n",
    "omega = 2 * np.pi / frequency\n",
    "gamma = 1.0 / damping_time\n",
    "A = np.linalg.inv(np.eye(2) - dt * np.array([[0.0, 1.0], [-omega**2, -gamma]]))\n",
    "\n",
    "process_noise = 3.0\n",
    "C = np.array([[0.0, 0.0],\n",
    "              [0.0, process_noise**2]])\n",
    "\n",
    "x0 = np.array([1.0, 0.0])\n",
    "\n",
    "num_cycles = 10\n",
    "num_timesteps = int(frequency / dt * num_cycles)\n",
    "\n",
    "# We can directly measure the oscillator position, but not its velocity.\n",
    "# The measurement matrix is not of full rank.\n",
    "M = np.array([[1.0, 0.0], [0.0, 0.0]])\n",
    "measurement_noise = 0.1\n",
    "Q = np.diag([measurement_noise**2, 10 * measurement_noise**2])\n",
    "\n",
    "x = np.zeros((num_timesteps + 1, 2))\n",
    "xp = np.zeros((num_timesteps + 1, 2))\n",
    "Cp = np.zeros((num_timesteps + 1, 2, 2))\n",
    "x[0, :] = x0\n",
    "xp[0, :] = x0\n",
    "Cp[0, :, :] = C\n",
    "for n in range(num_timesteps):\n",
    "    x[n + 1, :] = np.dot(A, x[n, :]) + dt * np.dot(C, np.random.randn(2))\n",
    "    y = np.dot(M, x[n + 1, :]) + np.dot(Q, np.random.randn(2))\n",
    "    \n",
    "    x_guess = np.dot(A, xp[n, :])\n",
    "    C_guess = np.dot(A, np.dot(Cp[n,:], A.T)) + C\n",
    "    \n",
    "    xp[n+1,:], Cp[n+1,:,:] = mle.update(x_guess, C_guess, y, M, Q)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x[:,0], x[:,1], color = 'b', hold = True)\n",
    "plt.plot(xp[:,0], xp[:,1], color = 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try switching which field we can observe (velocity instead of position) or changing the noise amplitude and see how well we can follow the trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizations\n",
    "\n",
    "* We could be estimating $x_k$ based on the entire time series of measurements, including measurements that occurred before and after $k$ (Kalman smoothing, hindcasting).\n",
    "* There can be deterministic forcing:\n",
    "$$ x_k = Ax_{k-1} + Bu_k + \\xi_k $$\n",
    "* The underlying dynamical system can be continuous (Kalman-Bucy filter, hybrid filtering):\n",
    "$$ \\dot x = Ax + \\xi_t $$\n",
    "* The underlying dynamical system need not be linear:\n",
    "$$ \\dot x = f(x) + \\xi_t $$\n",
    "Use the linearization of $f$ about the a priori estimate (extended Kalman filter).\n",
    "* The system can be large (think weather forecasting), in which case maintaining covariance matrices is expensive.\n",
    "Then we use an *ensemble* of representative solutions to estimate the true covariance (ensemble Kalman filter)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
